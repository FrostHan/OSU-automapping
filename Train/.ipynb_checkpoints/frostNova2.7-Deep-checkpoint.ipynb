{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "shutil.rmtree('D:/MATLAB/OSU/OSU-automapping/Train/log/', ignore_errors=True)\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TensorBoard-Piliang-logfre-frePooling-deep\n",
    "### Two groups of output\n",
    "\n",
    "- One classification output(1x2) for recognizing if there is a object, minimizing cross entropy using softmax\n",
    "- One fitting network(1x4) for deciding if a object should be a circle/sliderHead/sliderEnd, minimizing MSE using sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 2e-5\n",
    "channels_input = 64\n",
    "channels_output = 64\n",
    "gamma = 0.25 # relative strength of 4-D term\n",
    "\n",
    "fc_input_dim = int(128*128*channels_output/2**7/2**4)\n",
    "fc_hidden1_dim = 256\n",
    "fc_hidden2_dim = 256\n",
    "\n",
    "fc_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, dy=1 ,dx=1):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, dx, dy, 1], padding='SAME')\n",
    "    # Y: time X: frequency\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def max_pool_axb(x,a,b):\n",
    "    return tf.nn.max_pool(x, ksize=[1, a, b, 1], strides=[1, a, b, 1], padding='SAME')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "#     with tf.name_scope('summaries'):\n",
    "#         mean = tf.reduce_mean(var)\n",
    "#         tf.summary.scalar('mean', mean)\n",
    "#         with tf.name_scope('stddev'):\n",
    "#             stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "#         tf.summary.scalar('stddev', stddev)\n",
    "#         tf.summary.scalar('max', tf.reduce_max(var))\n",
    "#         tf.summary.scalar('min', tf.reduce_min(var))\n",
    "#         tf.summary.histogram('histogram', var)\n",
    "\n",
    "def conv_layer(input_tensor, filter_height, filter_width, channels_input, channels_output, layer_name, act=tf.nn.relu):\n",
    "  # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([filter_height, filter_width, channels_input, channels_output])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([channels_output])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = conv2d(input_tensor, weights,2,1) + biases\n",
    "#             tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "#         tf.summary.histogram('activations', activations)\n",
    "        return activations\n",
    "\n",
    "def fc_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "#             tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "#         tf.summary.histogram('activations', activations)\n",
    "        return activations\n",
    "    \n",
    "def output_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.softmax):\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "#             tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "#         tf.summary.histogram('activations', activations)\n",
    "        return activations \n",
    "\n",
    "def batch_norm_layer(x, train_phase, scope_bn):\n",
    "    with tf.variable_scope(scope_bn):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[x.shape[-1]]), name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[x.shape[-1]]), name='gamma', trainable=True)\n",
    "        axises = np.arange(len(x.shape) - 1)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, axises, name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(train_phase, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed    \n",
    "    \n",
    "########################   Structure   ##############################\n",
    "\n",
    "with tf.name_scope('spectrogram_input'):\n",
    "    x = tf.placeholder(\"float\", shape=[None, 128*128] , name='flat_input')\n",
    "with tf.name_scope('target'):\n",
    "    y_2 = tf.placeholder(\"float\", shape=[None, 2], name='target_2')\n",
    "    y_4 = tf.placeholder(\"float\", shape=[None, 4], name='target_4')\n",
    "with tf.name_scope('input'):\n",
    "    x_image = tf.reshape(x, [-1,128,128,1] , name='2D_input')\n",
    "\n",
    "h_conv1 = conv_layer(x_image, 16, 4,            1,      channels_output, 'conv_layer_1' , act=tf.nn.relu)\n",
    "h_conv1_pl = max_pool_axb(h_conv1, 2, 1)\n",
    "\n",
    "h_conv2 = conv_layer(h_conv1_pl, 4, 16, channels_input, channels_output, 'conv_layer_2' , act=tf.nn.relu)\n",
    "h_conv2_pl = max_pool_axb(h_conv2, 2, 1)\n",
    "\n",
    "h_conv3 = conv_layer(h_conv2_pl, 16, 4, channels_input, channels_output, 'conv_layer_3' , act=tf.nn.relu)\n",
    "h_conv3_pl = max_pool_axb(h_conv3, 2, 1)\n",
    "\n",
    "h_conv4 = conv_layer(h_conv3_pl, 4, 16, channels_input, channels_output, 'conv_layer_4' , act=tf.nn.relu)\n",
    "h_conv4_pl = max_pool_axb(h_conv4, 2, 1)\n",
    "\n",
    "h_conv5 = conv_layer(h_conv4_pl, 16, 4, channels_input, channels_output, 'conv_layer_5' , act=tf.nn.relu)\n",
    "h_conv5_pl = max_pool_axb(h_conv5, 1, 1)\n",
    "\n",
    "h_conv6 = conv_layer(h_conv5_pl, 4, 16, channels_input, channels_output, 'conv_layer_6' , act=tf.nn.relu)\n",
    "h_conv6_pl = max_pool_axb(h_conv6, 1, 1)\n",
    "\n",
    "h_conv7 = conv_layer(h_conv6_pl, 4, 4, channels_input, channels_output, 'conv_layer_7' , act=tf.nn.relu)\n",
    "h_conv7_pl = max_pool_axb(h_conv7, 1, 1)\n",
    "\n",
    "\n",
    "with tf.name_scope('reshape'):\n",
    "    h_before_fc = tf.reshape(h_conv7_pl, [-1,fc_input_dim])\n",
    "\n",
    "h_fc1 = fc_layer(h_before_fc, fc_input_dim, fc_hidden1_dim, 'hidden_layer_1' , act=tf.nn.relu)\n",
    "h_fc2 = fc_layer(h_fc1, fc_hidden1_dim, fc_hidden2_dim, 'hidden_layer_2' , act=tf.nn.relu)\n",
    "\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    h_fc_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    y2 = output_layer(h_fc_drop, fc_hidden2_dim, 2, 'output_layer_2D' , act=tf.nn.softmax)\n",
    "    y4 = output_layer(h_fc_drop, fc_hidden2_dim, 4, 'output_layer_4D' , act=tf.nn.sigmoid)\n",
    "    # tf.summary.histogram('y',y)\n",
    "\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        diff2 = - y_2 * tf.log(tf.clip_by_value(y2, 1e-20, 1.0))\n",
    "    with tf.name_scope('mean_squared_error'):\n",
    "        diff4 = tf.losses.mean_squared_error(y_4, y4)\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(diff2)\n",
    "    mse = tf.reduce_mean(diff4) \n",
    "    loss = cross_entropy + gamma * mse\n",
    "\n",
    "# tf.summary.histogram('cross_entropy_individual',diff)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "tf.summary.scalar('mse', mse)\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction_2'):\n",
    "        correct_prediction_2 = tf.equal(tf.argmax(y2, 1), tf.argmax(y_2, 1))\n",
    "    with tf.name_scope('accuracy_2'):\n",
    "        accuracy_2 = tf.reduce_mean(tf.cast(correct_prediction_2, tf.float32))\n",
    "    tf.summary.scalar('accuracy_2', accuracy_2)\n",
    "    \n",
    "    with tf.name_scope('correct_prediction_4'):\n",
    "        correct_prediction_4 = tf.equal(tf.argmax(y4, 1), tf.argmax(y_4, 1))\n",
    "    with tf.name_scope('accuracy_4'):\n",
    "        accuracy_4 = tf.reduce_mean(tf.cast(correct_prediction_4, tf.float32))\n",
    "    tf.summary.scalar('accuracy_4', accuracy_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################## Initialization & Read Data  #######################\n",
    "\n",
    "summaries_dir = 'D:/MATLAB/OSU/OSU-automapping/Train/log/train'+now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(summaries_dir + '/train',sess.graph)\n",
    "test_writer = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# Test Data\n",
    "\n",
    "testData = sio.loadmat('D:/OSU/SongMat/Test/532522 SakiZ - osu!memories.mat')\n",
    "inputTest = testData['input'].reshape(-1,128*128)\n",
    "targetTest = testData['target'].reshape(-1,4)\n",
    "\n",
    "targetTest2 = np.zeros([targetTest.shape[0],2])\n",
    "targetTest2[:,0] = targetTest[:,0]+targetTest[:,1]+targetTest[:,2]\n",
    "targetTest2[:,1] = targetTest[:,3]\n",
    "\n",
    "targetTest4 = np.zeros([targetTest.shape[0],4])\n",
    "targetTest4[:,0] = targetTest[:,0] + 0.5*targetTest[:,1] + 0.5*targetTest[:,2]\n",
    "targetTest4[:,1] = 0.5*targetTest[:,0] + targetTest[:,1] + 0.5*targetTest[:,2]\n",
    "targetTest4[:,2] = 0.5*targetTest[:,0] + 0.5*targetTest[:,1] + targetTest[:,2]\n",
    "targetTest4[:,3] = targetTest[:,3]\n",
    "\n",
    "    \n",
    "NTest=targetTest2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17803\n",
      "step 00000, memory accuracy (2D)  0.54, memory accuracy (4D)  0.16\n",
      "step 01000, memory accuracy (2D)  0.54, memory accuracy (4D) 0.237\n",
      "step 02000, memory accuracy (2D) 0.537, memory accuracy (4D) 0.257\n",
      "step 03000, memory accuracy (2D)  0.54, memory accuracy (4D)  0.21\n",
      "step 04000, memory accuracy (2D)  0.54, memory accuracy (4D)  0.24\n",
      "step 05000, memory accuracy (2D) 0.557, memory accuracy (4D) 0.327\n",
      "step 06000, memory accuracy (2D)  0.55, memory accuracy (4D) 0.393\n",
      "step 07000, memory accuracy (2D) 0.597, memory accuracy (4D) 0.423\n",
      "step 08000, memory accuracy (2D)  0.56, memory accuracy (4D)  0.41\n",
      "step 09000, memory accuracy (2D) 0.607, memory accuracy (4D) 0.397\n",
      "step 10000, memory accuracy (2D) 0.653, memory accuracy (4D) 0.363\n",
      "step 11000, memory accuracy (2D)  0.61, memory accuracy (4D) 0.287\n",
      "step 12000, memory accuracy (2D) 0.703, memory accuracy (4D) 0.367\n",
      "step 13000, memory accuracy (2D) 0.717, memory accuracy (4D) 0.387\n",
      "step 14000, memory accuracy (2D)  0.72, memory accuracy (4D)  0.42\n",
      "step 15000, memory accuracy (2D)  0.69, memory accuracy (4D) 0.413\n",
      "step 16000, memory accuracy (2D) 0.733, memory accuracy (4D)  0.41\n",
      "step 17000, memory accuracy (2D) 0.713, memory accuracy (4D)  0.44\n",
      "17923\n",
      "step 00000, memory accuracy (2D) 0.677, memory accuracy (4D) 0.487\n",
      "step 01000, memory accuracy (2D) 0.743, memory accuracy (4D) 0.493\n",
      "step 02000, memory accuracy (2D) 0.743, memory accuracy (4D) 0.483\n",
      "step 03000, memory accuracy (2D) 0.773, memory accuracy (4D) 0.447\n",
      "step 04000, memory accuracy (2D) 0.777, memory accuracy (4D)  0.45\n",
      "step 05000, memory accuracy (2D)  0.76, memory accuracy (4D)  0.45\n",
      "step 06000, memory accuracy (2D) 0.787, memory accuracy (4D) 0.367\n",
      "step 07000, memory accuracy (2D) 0.723, memory accuracy (4D)  0.35\n",
      "step 08000, memory accuracy (2D) 0.777, memory accuracy (4D)  0.44\n",
      "step 09000, memory accuracy (2D) 0.763, memory accuracy (4D) 0.443\n",
      "step 10000, memory accuracy (2D) 0.763, memory accuracy (4D) 0.427\n",
      "step 11000, memory accuracy (2D) 0.763, memory accuracy (4D) 0.287\n",
      "step 12000, memory accuracy (2D)  0.79, memory accuracy (4D) 0.407\n",
      "step 13000, memory accuracy (2D)  0.78, memory accuracy (4D) 0.447\n",
      "step 14000, memory accuracy (2D) 0.763, memory accuracy (4D) 0.457\n",
      "step 15000, memory accuracy (2D) 0.777, memory accuracy (4D)  0.44\n",
      "step 16000, memory accuracy (2D)   0.7, memory accuracy (4D)   0.4\n",
      "step 17000, memory accuracy (2D) 0.787, memory accuracy (4D) 0.347\n",
      "17316\n",
      "step 00000, memory accuracy (2D) 0.677, memory accuracy (4D) 0.327\n",
      "step 01000, memory accuracy (2D) 0.773, memory accuracy (4D) 0.263\n",
      "step 02000, memory accuracy (2D) 0.733, memory accuracy (4D) 0.323\n",
      "step 03000, memory accuracy (2D) 0.763, memory accuracy (4D) 0.363\n",
      "step 04000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.357\n",
      "step 05000, memory accuracy (2D) 0.737, memory accuracy (4D) 0.293\n",
      "step 06000, memory accuracy (2D) 0.763, memory accuracy (4D)  0.38\n",
      "step 07000, memory accuracy (2D) 0.753, memory accuracy (4D)  0.43\n",
      "step 08000, memory accuracy (2D) 0.733, memory accuracy (4D) 0.417\n",
      "step 09000, memory accuracy (2D)  0.77, memory accuracy (4D) 0.463\n",
      "step 10000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.487\n",
      "step 11000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.487\n",
      "step 12000, memory accuracy (2D)  0.71, memory accuracy (4D)  0.41\n",
      "step 13000, memory accuracy (2D)  0.75, memory accuracy (4D)  0.32\n",
      "step 14000, memory accuracy (2D) 0.723, memory accuracy (4D)  0.25\n",
      "step 15000, memory accuracy (2D)  0.76, memory accuracy (4D)  0.32\n",
      "step 16000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.283\n",
      "step 17000, memory accuracy (2D) 0.737, memory accuracy (4D) 0.303\n",
      "14253\n",
      "step 00000, memory accuracy (2D)  0.74, memory accuracy (4D) 0.357\n",
      "step 01000, memory accuracy (2D) 0.733, memory accuracy (4D) 0.323\n",
      "step 02000, memory accuracy (2D)  0.74, memory accuracy (4D)  0.34\n",
      "step 03000, memory accuracy (2D) 0.727, memory accuracy (4D) 0.353\n",
      "step 04000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.343\n",
      "step 05000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.333\n",
      "step 06000, memory accuracy (2D) 0.733, memory accuracy (4D)  0.38\n",
      "step 07000, memory accuracy (2D) 0.747, memory accuracy (4D) 0.407\n",
      "step 08000, memory accuracy (2D) 0.747, memory accuracy (4D) 0.343\n",
      "step 09000, memory accuracy (2D)  0.74, memory accuracy (4D) 0.323\n",
      "step 10000, memory accuracy (2D) 0.743, memory accuracy (4D)  0.34\n",
      "step 11000, memory accuracy (2D) 0.747, memory accuracy (4D) 0.357\n",
      "step 12000, memory accuracy (2D) 0.747, memory accuracy (4D)  0.36\n",
      "step 13000, memory accuracy (2D) 0.753, memory accuracy (4D) 0.313\n",
      "step 14000, memory accuracy (2D)  0.73, memory accuracy (4D) 0.277\n",
      "17204\n",
      "step 00000, memory accuracy (2D) 0.713, memory accuracy (4D) 0.273\n",
      "step 01000, memory accuracy (2D) 0.737, memory accuracy (4D) 0.283\n",
      "step 02000, memory accuracy (2D)  0.72, memory accuracy (4D) 0.293\n",
      "step 03000, memory accuracy (2D) 0.723, memory accuracy (4D)  0.34\n",
      "step 04000, memory accuracy (2D) 0.723, memory accuracy (4D) 0.333\n",
      "step 05000, memory accuracy (2D) 0.753, memory accuracy (4D)  0.31\n",
      "step 06000, memory accuracy (2D) 0.747, memory accuracy (4D) 0.313\n",
      "step 07000, memory accuracy (2D) 0.757, memory accuracy (4D) 0.337\n",
      "step 08000, memory accuracy (2D)  0.68, memory accuracy (4D)  0.33\n",
      "step 09000, memory accuracy (2D) 0.743, memory accuracy (4D) 0.363\n",
      "step 10000, memory accuracy (2D) 0.743, memory accuracy (4D) 0.343\n",
      "step 11000, memory accuracy (2D) 0.733, memory accuracy (4D) 0.293\n",
      "step 12000, memory accuracy (2D) 0.727, memory accuracy (4D) 0.297\n",
      "step 13000, memory accuracy (2D)  0.75, memory accuracy (4D) 0.333\n",
      "step 14000, memory accuracy (2D) 0.767, memory accuracy (4D) 0.313\n",
      "step 15000, memory accuracy (2D) 0.753, memory accuracy (4D)  0.26\n",
      "step 16000, memory accuracy (2D)  0.74, memory accuracy (4D)  0.27\n",
      "step 17000, memory accuracy (2D) 0.707, memory accuracy (4D)  0.32\n",
      "14950\n",
      "step 00000, memory accuracy (2D) 0.713, memory accuracy (4D) 0.327\n",
      "step 01000, memory accuracy (2D)  0.73, memory accuracy (4D) 0.317\n",
      "step 02000, memory accuracy (2D)   0.7, memory accuracy (4D)  0.35\n",
      "step 03000, memory accuracy (2D)  0.71, memory accuracy (4D) 0.397\n",
      "step 04000, memory accuracy (2D)  0.71, memory accuracy (4D) 0.397\n",
      "step 05000, memory accuracy (2D) 0.713, memory accuracy (4D) 0.347\n",
      "step 06000, memory accuracy (2D) 0.697, memory accuracy (4D) 0.353\n",
      "step 07000, memory accuracy (2D)   0.7, memory accuracy (4D) 0.347\n",
      "step 08000, memory accuracy (2D)  0.71, memory accuracy (4D) 0.353\n",
      "step 09000, memory accuracy (2D) 0.713, memory accuracy (4D)  0.39\n",
      "step 10000, memory accuracy (2D) 0.747, memory accuracy (4D) 0.383\n",
      "step 11000, memory accuracy (2D)  0.71, memory accuracy (4D) 0.323\n",
      "step 12000, memory accuracy (2D) 0.717, memory accuracy (4D)   0.3\n",
      "step 13000, memory accuracy (2D)  0.73, memory accuracy (4D) 0.353\n",
      "step 14000, memory accuracy (2D)  0.74, memory accuracy (4D) 0.423\n",
      "15829\n",
      "step 00000, memory accuracy (2D) 0.733, memory accuracy (4D) 0.443\n",
      "step 01000, memory accuracy (2D) 0.703, memory accuracy (4D)  0.45\n",
      "step 02000, memory accuracy (2D) 0.727, memory accuracy (4D) 0.487\n",
      "step 03000, memory accuracy (2D) 0.743, memory accuracy (4D) 0.483\n",
      "step 04000, memory accuracy (2D) 0.733, memory accuracy (4D)  0.46\n",
      "step 05000, memory accuracy (2D) 0.717, memory accuracy (4D) 0.437\n",
      "step 06000, memory accuracy (2D) 0.727, memory accuracy (4D) 0.443\n",
      "step 07000, memory accuracy (2D) 0.727, memory accuracy (4D)  0.45\n",
      "step 08000, memory accuracy (2D)  0.72, memory accuracy (4D)  0.45\n",
      "step 09000, memory accuracy (2D) 0.743, memory accuracy (4D)  0.47\n",
      "step 10000, memory accuracy (2D)  0.76, memory accuracy (4D)  0.49\n",
      "step 11000, memory accuracy (2D) 0.747, memory accuracy (4D)  0.47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7ee29aeeb705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputOsu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargetOsu2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_4\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargetOsu4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[0mtest_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#         else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################## Training  #######################\n",
    "\n",
    "# batch_size = 20\n",
    "step_size = 100\n",
    "dataList=os.listdir('D:/OSU/SongMat/Train/')\n",
    "# acc=np.zeros([1000,1])\n",
    "\n",
    "n = 1\n",
    "total_steps = 0\n",
    "while n < np.size(dataList)-18:\n",
    "    n = n + 3\n",
    "    inputOsu=np.empty([0,128*128])\n",
    "    targetOsu=np.empty([0,4])\n",
    "    for k in range(n,n+15):\n",
    "        \n",
    "        data=sio.loadmat('D:/OSU/SongMat/Train/'+dataList[k])\n",
    "        inputOsu=np.append(inputOsu,data['input1'].reshape(-1,128*128),axis=0)\n",
    "        targetOsu=np.append(targetOsu,data['target1'].reshape(-1,4),axis=0)\n",
    "               \n",
    "    targetOsu2 = np.zeros([targetOsu.shape[0],2]);\n",
    "    targetOsu2[:,0] = targetOsu[:,0] + targetOsu[:,1] + targetOsu[:,2]\n",
    "    targetOsu2[:,1] = targetOsu[:,3]\n",
    "    \n",
    "    targetOsu4 = np.zeros([targetOsu.shape[0],4])\n",
    "    targetOsu4[:,0] = targetOsu[:,0] + 0.5*targetOsu[:,1] + 0.5*targetOsu[:,2]\n",
    "    targetOsu4[:,1] = 0.5*targetOsu[:,0] + targetOsu[:,1] + 0.5*targetOsu[:,2]\n",
    "    targetOsu4[:,2] = 0.5*targetOsu[:,0] + 0.5*targetOsu[:,1] + targetOsu[:,2]\n",
    "    targetOsu4[:,3] = targetOsu[:,3]\n",
    "    \n",
    "    N=inputOsu.shape[0]\n",
    "    print(N)\n",
    "    \n",
    "    #shuffle the order\n",
    "    order = np.arange(N-step_size)\n",
    "    np.random.shuffle(order)\n",
    "    orderAcc = np.arange(NTest)\n",
    "    np.random.shuffle(orderAcc)\n",
    "    \n",
    "    for i in range(N-step_size):\n",
    "        if i%step_size == 0:\n",
    "            summary, _  = sess.run([merged, train_step], feed_dict={x: inputOsu[order[i:i+step_size],:], y_2: targetOsu2[order[i:i+step_size],:], y_4: targetOsu4[order[i:i+step_size],:], keep_prob: 0.5})\n",
    "            test_writer.add_summary(summary, i + total_steps)\n",
    "#         else:\n",
    "#             summary = sess.run(merged, feed_dict={x: inputOsu[order[i:i+step_size],:], y_2: targetOsu2[order[i:i+step_size],:], y_4: targetOsu4[order[i:i+step_size],:], keep_prob: 0.5})\n",
    "#             train_writer.add_summary(summary, i + total_steps)\n",
    "        if i%1000 == 0:\n",
    "            accMemory_2 = accuracy_2.eval(feed_dict={x: inputTest[orderAcc[0:300],:], y_2: targetTest2[orderAcc[0:300],:],  y_4: targetTest4[orderAcc[0:300],:], keep_prob: 1.0}) \n",
    "            accMemory_4 = accuracy_4.eval(feed_dict={x: inputTest[orderAcc[0:300],:], y_2: targetTest2[orderAcc[0:300],:],  y_4: targetTest4[orderAcc[0:300],:], keep_prob: 1.0}) \n",
    "            print(\"step %5.5d, memory accuracy (2D) %5.3g, memory accuracy (4D) %5.3g\" %(i, accMemory_2, accMemory_4))\n",
    "#             print(y.eval(feed_dict={x: inputTest[orderAcc[1122:1130],:], keep_prob: 1.0}))\n",
    "            \n",
    "    total_steps += i\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"D:/OSU/results/save/2.7/\",global_step=n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Save the output of new maps ##############################\n",
    "\n",
    "dataList=os.listdir('C:/OSU/SongMat/Create/')\n",
    "# inputOsuNew=np.empty([0,128*128]);\n",
    "for i in range(np.size(dataList)):\n",
    "    if not dataList[i][0]=='y':\n",
    "        data=sio.loadmat('C:/OSU/SongMat/Create/'+dataList[i])\n",
    "        print(data['osuFolder'])\n",
    "        \n",
    "        inputOsuNew=data['input'].reshape(-1,128*128)\n",
    "        outputOsuNew=data['target']\n",
    "        outputOsu2New=np.zeros([outputOsuNew.shape[0],2]);\n",
    "        outputOsu2New[:,0]=outputOsuNew[:,0]+outputOsuNew[:,1]+outputOsuNew[:,2]\n",
    "        outputOsu2New[:,1]=outputOsuNew[:,3]\n",
    "        \n",
    "        y_result_2 = np.empty([0,2])\n",
    "        y_result_4 = np.empty([0,4])\n",
    "        step_size = 100\n",
    "        cursor = 0\n",
    "        \n",
    "        print (\"test accuracy %g\"%accuracy_2.eval(feed_dict={x: inputOsuNew[-300:,:], y_2: outputOsu2New[-300:,:], keep_prob: 1.0}))\n",
    "        while cursor < inputOsuNew.shape[0]:\n",
    "            if inputOsuNew[cursor:,:].shape[0] > step_size:\n",
    "                y_result_2_1 = y2.eval(feed_dict={x: inputOsuNew[cursor:(cursor+step_size):1,:], keep_prob: 1.0})\n",
    "                y_result_4_1 = y4.eval(feed_dict={x: inputOsuNew[cursor:(cursor+step_size):1,:], keep_prob: 1.0})\n",
    "                y_result_2 = np.append(y_result_2,y_result_2_1,axis=0)\n",
    "                y_result_4 = np.append(y_result_4,y_result_4_1,axis=0)\n",
    "            else:\n",
    "                y_result_2_1 = y2.eval(feed_dict={x: inputOsuNew[cursor:(cursor+step_size):1,:], keep_prob: 1.0})\n",
    "                y_result_4_1 = y4.eval(feed_dict={x: inputOsuNew[cursor:(cursor+step_size):1,:], keep_prob: 1.0})\n",
    "                y_result_2 = np.append(y_result_2,y_result_2_1,axis=0)\n",
    "                y_result_4 = np.append(y_result_4,y_result_4_1,axis=0)\n",
    "            cursor+=step_size\n",
    "            \n",
    "        data_save={'y2':y_result_2, 'y4':y_result_4}\n",
    "\n",
    "        sio.savemat('C:/OSU/SongMat/Create/y_'+dataList[i],data_save)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
