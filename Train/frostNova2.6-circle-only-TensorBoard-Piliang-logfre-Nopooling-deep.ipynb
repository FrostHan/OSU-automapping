{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "shutil.rmtree('D:/MATLAB/OSU/OSU-automapping/Train/log/', ignore_errors=True)\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "channels_input = 32\n",
    "channels_output = 32\n",
    "\n",
    "fc_input_dim = int(128*128*channels_output/4**4)\n",
    "fc_hidden_dim = 128\n",
    "\n",
    "fc_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, dy=1 ,dx=1):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, dx, dy, 1], padding='SAME')\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "#     with tf.name_scope('summaries'):\n",
    "#         mean = tf.reduce_mean(var)\n",
    "#         tf.summary.scalar('mean', mean)\n",
    "#         with tf.name_scope('stddev'):\n",
    "#             stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "#         tf.summary.scalar('stddev', stddev)\n",
    "#         tf.summary.scalar('max', tf.reduce_max(var))\n",
    "#         tf.summary.scalar('min', tf.reduce_min(var))\n",
    "#         tf.summary.histogram('histogram', var)\n",
    "\n",
    "def conv_layer(input_tensor, filter_height, filter_width, channels_input, channels_output, layer_name, act=tf.nn.relu):\n",
    "  # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([filter_height, filter_width, channels_input, channels_output])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([channels_output])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = conv2d(input_tensor, weights,2,2) + biases\n",
    "#             tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "#         tf.summary.histogram('activations', activations)\n",
    "        return activations\n",
    "\n",
    "def fc_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "#             tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "#         tf.summary.histogram('activations', activations)\n",
    "        return activations\n",
    "    \n",
    "def output_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.softmax):\n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "    # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "#             tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "#         tf.summary.histogram('activations', activations)\n",
    "        return activations \n",
    "\n",
    "def batch_norm_layer(x, train_phase, scope_bn):\n",
    "    with tf.variable_scope(scope_bn):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[x.shape[-1]]), name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[x.shape[-1]]), name='gamma', trainable=True)\n",
    "        axises = np.arange(len(x.shape) - 1)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, axises, name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(train_phase, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed    \n",
    "    \n",
    "########################   Structure   ##############################\n",
    "\n",
    "with tf.name_scope('spectrogram_input'):\n",
    "    x = tf.placeholder(\"float\", shape=[None, 128*128] , name='flat_input')\n",
    "with tf.name_scope('target'):\n",
    "    y_ = tf.placeholder(\"float\", shape=[None, 2] , name='target')\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x_image = tf.reshape(x, [-1,128,128,1] , name='2D_input')\n",
    "\n",
    "h_conv1 = conv_layer(x_image, 16, 4, 1,              channels_output, 'conv_layer_1' , act=tf.nn.relu)\n",
    "h_conv2 = conv_layer(h_conv1, 4, 16, channels_input, channels_output, 'conv_layer_2' , act=tf.nn.relu)\n",
    "h_conv3 = conv_layer(h_conv2, 16, 4, channels_input, channels_output, 'conv_layer_3' , act=tf.nn.relu)\n",
    "h_conv4 = conv_layer(h_conv3, 4, 16, channels_input, channels_output, 'conv_layer_4' , act=tf.nn.relu)\n",
    "\n",
    "with tf.name_scope('reshape'):\n",
    "    h_before_fc = tf.reshape(h_conv4,[-1,fc_input_dim])\n",
    "\n",
    "h_fc = fc_layer(h_before_fc, fc_input_dim, fc_hidden_dim, 'hidden_layer' , act=tf.nn.relu)\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    h_fc_drop = tf.nn.dropout(h_fc, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = output_layer(h_fc_drop, fc_hidden_dim, 2, 'output_layer_1' , act=tf.nn.softmax)\n",
    "# tf.summary.histogram('y',y)\n",
    "\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    diff = -y_*tf.log(tf.clip_by_value(y,1e-20,1.0))\n",
    "    cross_entropy = tf.reduce_mean(diff)\n",
    "\n",
    "# tf.summary.histogram('cross_entropy_individual',diff)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################## Initialization & Read Data  #######################\n",
    "\n",
    "summaries_dir = 'D:/MATLAB/OSU/OSU-automapping/Train/log/train'+now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(summaries_dir + '/train',sess.graph)\n",
    "test_writer = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# Test Data\n",
    "\n",
    "testData=sio.loadmat('C:/OSU/SongMat/Test/532522 SakiZ - osu!memories.mat')\n",
    "inputTest=testData['input'].reshape(-1,128*128)\n",
    "targetTest=testData['target'].reshape(-1,4)\n",
    "targetTest2=np.zeros([targetTest.shape[0],2])\n",
    "targetTest2[:,0]=targetTest[:,0]+targetTest[:,1]+targetTest[:,2]\n",
    "targetTest2[:,1]=targetTest[:,3]\n",
    "\n",
    "NTest=targetTest2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17803\n",
      "step 0, memory accuracy 0.55\n",
      "step 1000, memory accuracy 0.574\n",
      "step 2000, memory accuracy 0.602\n",
      "step 3000, memory accuracy 0.568\n",
      "step 4000, memory accuracy 0.588\n",
      "step 5000, memory accuracy 0.606\n",
      "step 6000, memory accuracy 0.628\n",
      "step 7000, memory accuracy 0.64\n",
      "step 8000, memory accuracy 0.63\n",
      "step 9000, memory accuracy 0.66\n",
      "step 10000, memory accuracy 0.654\n",
      "step 11000, memory accuracy 0.646\n",
      "step 12000, memory accuracy 0.632\n",
      "step 13000, memory accuracy 0.682\n",
      "step 14000, memory accuracy 0.692\n",
      "step 15000, memory accuracy 0.676\n",
      "step 16000, memory accuracy 0.678\n",
      "step 17000, memory accuracy 0.696\n",
      "17923\n",
      "step 0, memory accuracy 0.736\n",
      "step 1000, memory accuracy 0.716\n",
      "step 2000, memory accuracy 0.73\n",
      "step 3000, memory accuracy 0.738\n",
      "step 4000, memory accuracy 0.71\n",
      "step 5000, memory accuracy 0.732\n",
      "step 6000, memory accuracy 0.758\n",
      "step 7000, memory accuracy 0.732\n",
      "step 8000, memory accuracy 0.74\n",
      "step 9000, memory accuracy 0.756\n",
      "step 10000, memory accuracy 0.756\n",
      "step 11000, memory accuracy 0.75\n",
      "step 12000, memory accuracy 0.774\n",
      "step 13000, memory accuracy 0.74\n",
      "step 14000, memory accuracy 0.8\n",
      "step 15000, memory accuracy 0.798\n",
      "step 16000, memory accuracy 0.768\n",
      "step 17000, memory accuracy 0.796\n",
      "17316\n",
      "step 0, memory accuracy 0.73\n",
      "step 1000, memory accuracy 0.758\n",
      "step 2000, memory accuracy 0.784\n",
      "step 3000, memory accuracy 0.734\n",
      "step 4000, memory accuracy 0.79\n",
      "step 5000, memory accuracy 0.782\n",
      "step 6000, memory accuracy 0.78\n",
      "step 7000, memory accuracy 0.796\n",
      "step 8000, memory accuracy 0.746\n",
      "step 9000, memory accuracy 0.788\n",
      "step 10000, memory accuracy 0.8\n",
      "step 11000, memory accuracy 0.788\n",
      "step 12000, memory accuracy 0.8\n",
      "step 13000, memory accuracy 0.784\n",
      "step 14000, memory accuracy 0.772\n",
      "step 15000, memory accuracy 0.77\n",
      "step 16000, memory accuracy 0.754\n",
      "step 17000, memory accuracy 0.81\n",
      "14253\n",
      "step 0, memory accuracy 0.79\n",
      "step 1000, memory accuracy 0.778\n",
      "step 2000, memory accuracy 0.784\n",
      "step 3000, memory accuracy 0.798\n",
      "step 4000, memory accuracy 0.774\n",
      "step 5000, memory accuracy 0.784\n",
      "step 6000, memory accuracy 0.794\n",
      "step 7000, memory accuracy 0.79\n",
      "step 8000, memory accuracy 0.778\n",
      "step 9000, memory accuracy 0.788\n",
      "step 10000, memory accuracy 0.764\n",
      "step 11000, memory accuracy 0.788\n",
      "step 12000, memory accuracy 0.8\n",
      "step 13000, memory accuracy 0.8\n",
      "step 14000, memory accuracy 0.756\n",
      "17204\n",
      "step 0, memory accuracy 0.726\n",
      "step 1000, memory accuracy 0.766\n",
      "step 2000, memory accuracy 0.718\n",
      "step 3000, memory accuracy 0.756\n",
      "step 4000, memory accuracy 0.758\n",
      "step 5000, memory accuracy 0.73\n",
      "step 6000, memory accuracy 0.738\n",
      "step 7000, memory accuracy 0.744\n",
      "step 8000, memory accuracy 0.752\n",
      "step 9000, memory accuracy 0.75\n",
      "step 10000, memory accuracy 0.732\n",
      "step 11000, memory accuracy 0.77\n",
      "step 12000, memory accuracy 0.756\n",
      "step 13000, memory accuracy 0.774\n",
      "step 14000, memory accuracy 0.754\n",
      "step 15000, memory accuracy 0.76\n",
      "step 16000, memory accuracy 0.76\n",
      "step 17000, memory accuracy 0.746\n",
      "14950\n",
      "step 0, memory accuracy 0.744\n",
      "step 1000, memory accuracy 0.766\n",
      "step 2000, memory accuracy 0.78\n",
      "step 3000, memory accuracy 0.722\n",
      "step 4000, memory accuracy 0.796\n",
      "step 5000, memory accuracy 0.742\n",
      "step 6000, memory accuracy 0.8\n",
      "step 7000, memory accuracy 0.762\n",
      "step 8000, memory accuracy 0.766\n",
      "step 9000, memory accuracy 0.796\n",
      "step 10000, memory accuracy 0.77\n",
      "step 11000, memory accuracy 0.78\n",
      "step 12000, memory accuracy 0.74\n",
      "step 13000, memory accuracy 0.752\n",
      "step 14000, memory accuracy 0.774\n",
      "15829\n",
      "step 0, memory accuracy 0.798\n",
      "step 1000, memory accuracy 0.81\n",
      "step 2000, memory accuracy 0.79\n",
      "step 3000, memory accuracy 0.812\n",
      "step 4000, memory accuracy 0.802\n",
      "step 5000, memory accuracy 0.778\n",
      "step 6000, memory accuracy 0.812\n",
      "step 7000, memory accuracy 0.816\n",
      "step 8000, memory accuracy 0.806\n",
      "step 9000, memory accuracy 0.808\n",
      "step 10000, memory accuracy 0.796\n",
      "step 11000, memory accuracy 0.792\n",
      "step 12000, memory accuracy 0.81\n",
      "step 13000, memory accuracy 0.816\n",
      "step 14000, memory accuracy 0.816\n",
      "step 15000, memory accuracy 0.794\n",
      "17424\n",
      "step 0, memory accuracy 0.77\n",
      "step 1000, memory accuracy 0.78\n",
      "step 2000, memory accuracy 0.782\n",
      "step 3000, memory accuracy 0.792\n",
      "step 4000, memory accuracy 0.788\n",
      "step 5000, memory accuracy 0.784\n",
      "step 6000, memory accuracy 0.776\n",
      "step 7000, memory accuracy 0.788\n",
      "step 8000, memory accuracy 0.788\n",
      "step 9000, memory accuracy 0.794\n",
      "step 10000, memory accuracy 0.788\n",
      "step 11000, memory accuracy 0.788\n",
      "step 12000, memory accuracy 0.762\n",
      "step 13000, memory accuracy 0.78\n",
      "step 14000, memory accuracy 0.792\n",
      "step 15000, memory accuracy 0.776\n",
      "step 16000, memory accuracy 0.79\n",
      "step 17000, memory accuracy 0.796\n",
      "21556\n",
      "step 0, memory accuracy 0.802\n",
      "step 1000, memory accuracy 0.814\n",
      "step 2000, memory accuracy 0.8\n",
      "step 3000, memory accuracy 0.822\n",
      "step 4000, memory accuracy 0.816\n",
      "step 5000, memory accuracy 0.826\n",
      "step 6000, memory accuracy 0.822\n",
      "step 7000, memory accuracy 0.816\n",
      "step 8000, memory accuracy 0.816\n",
      "step 9000, memory accuracy 0.818\n",
      "step 10000, memory accuracy 0.814\n",
      "step 11000, memory accuracy 0.812\n",
      "step 12000, memory accuracy 0.824\n",
      "step 13000, memory accuracy 0.824\n",
      "step 14000, memory accuracy 0.82\n",
      "step 15000, memory accuracy 0.82\n",
      "step 16000, memory accuracy 0.818\n",
      "step 17000, memory accuracy 0.822\n",
      "step 18000, memory accuracy 0.82\n",
      "step 19000, memory accuracy 0.83\n",
      "step 20000, memory accuracy 0.826\n",
      "step 21000, memory accuracy 0.818\n",
      "22131\n",
      "step 0, memory accuracy 0.816\n",
      "step 1000, memory accuracy 0.816\n",
      "step 2000, memory accuracy 0.818\n",
      "step 3000, memory accuracy 0.822\n",
      "step 4000, memory accuracy 0.814\n",
      "step 5000, memory accuracy 0.794\n",
      "step 6000, memory accuracy 0.822\n",
      "step 7000, memory accuracy 0.784\n",
      "step 8000, memory accuracy 0.814\n",
      "step 9000, memory accuracy 0.804\n",
      "step 10000, memory accuracy 0.814\n",
      "step 11000, memory accuracy 0.816\n",
      "step 12000, memory accuracy 0.812\n",
      "step 13000, memory accuracy 0.818\n",
      "step 14000, memory accuracy 0.82\n",
      "step 15000, memory accuracy 0.818\n",
      "step 16000, memory accuracy 0.816\n",
      "step 17000, memory accuracy 0.812\n",
      "step 18000, memory accuracy 0.814\n",
      "step 19000, memory accuracy 0.824\n",
      "step 20000, memory accuracy 0.824\n",
      "step 21000, memory accuracy 0.812\n",
      "step 22000, memory accuracy 0.822\n",
      "25692\n",
      "step 0, memory accuracy 0.802\n",
      "step 1000, memory accuracy 0.782\n",
      "step 2000, memory accuracy 0.794\n",
      "step 3000, memory accuracy 0.796\n",
      "step 4000, memory accuracy 0.796\n",
      "step 5000, memory accuracy 0.8\n",
      "step 6000, memory accuracy 0.802\n",
      "step 7000, memory accuracy 0.796\n",
      "step 8000, memory accuracy 0.798\n",
      "step 9000, memory accuracy 0.792\n",
      "step 10000, memory accuracy 0.786\n",
      "step 11000, memory accuracy 0.796\n",
      "step 12000, memory accuracy 0.8\n",
      "step 13000, memory accuracy 0.804\n",
      "step 14000, memory accuracy 0.802\n",
      "step 15000, memory accuracy 0.808\n",
      "step 16000, memory accuracy 0.808\n",
      "step 17000, memory accuracy 0.806\n",
      "step 18000, memory accuracy 0.784\n",
      "step 19000, memory accuracy 0.796\n",
      "step 20000, memory accuracy 0.794\n",
      "step 21000, memory accuracy 0.798\n",
      "step 22000, memory accuracy 0.806\n",
      "step 23000, memory accuracy 0.802\n",
      "step 24000, memory accuracy 0.802\n",
      "step 25000, memory accuracy 0.8\n",
      "26258\n",
      "step 0, memory accuracy 0.808\n",
      "step 1000, memory accuracy 0.812\n",
      "step 2000, memory accuracy 0.816\n",
      "step 3000, memory accuracy 0.808\n",
      "step 4000, memory accuracy 0.808\n",
      "step 5000, memory accuracy 0.804\n",
      "step 6000, memory accuracy 0.806\n",
      "step 7000, memory accuracy 0.814\n",
      "step 8000, memory accuracy 0.816\n",
      "step 9000, memory accuracy 0.818\n",
      "step 10000, memory accuracy 0.816\n",
      "step 11000, memory accuracy 0.812\n",
      "step 12000, memory accuracy 0.828\n",
      "step 13000, memory accuracy 0.82\n",
      "step 14000, memory accuracy 0.818\n",
      "step 15000, memory accuracy 0.816\n",
      "step 16000, memory accuracy 0.82\n",
      "step 17000, memory accuracy 0.822\n",
      "step 18000, memory accuracy 0.828\n",
      "step 19000, memory accuracy 0.82\n",
      "step 20000, memory accuracy 0.818\n",
      "step 21000, memory accuracy 0.824\n",
      "step 22000, memory accuracy 0.818\n",
      "step 23000, memory accuracy 0.81\n",
      "step 24000, memory accuracy 0.816\n",
      "step 25000, memory accuracy 0.814\n",
      "step 26000, memory accuracy 0.812\n",
      "26349\n",
      "step 0, memory accuracy 0.8\n",
      "step 1000, memory accuracy 0.8\n",
      "step 2000, memory accuracy 0.812\n",
      "step 3000, memory accuracy 0.806\n",
      "step 4000, memory accuracy 0.81\n",
      "step 5000, memory accuracy 0.8\n",
      "step 6000, memory accuracy 0.79\n",
      "step 7000, memory accuracy 0.8\n",
      "step 8000, memory accuracy 0.804\n",
      "step 9000, memory accuracy 0.804\n",
      "step 10000, memory accuracy 0.796\n",
      "step 11000, memory accuracy 0.798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12000, memory accuracy 0.804\n",
      "step 13000, memory accuracy 0.796\n",
      "step 14000, memory accuracy 0.798\n",
      "step 15000, memory accuracy 0.79\n",
      "step 16000, memory accuracy 0.8\n",
      "step 17000, memory accuracy 0.796\n",
      "step 18000, memory accuracy 0.8\n",
      "step 19000, memory accuracy 0.79\n",
      "step 20000, memory accuracy 0.802\n",
      "step 21000, memory accuracy 0.806\n",
      "step 22000, memory accuracy 0.8\n",
      "step 23000, memory accuracy 0.808\n",
      "step 24000, memory accuracy 0.81\n",
      "step 25000, memory accuracy 0.804\n",
      "step 26000, memory accuracy 0.804\n",
      "23437\n",
      "step 0, memory accuracy 0.834\n",
      "step 1000, memory accuracy 0.832\n",
      "step 2000, memory accuracy 0.84\n",
      "step 3000, memory accuracy 0.842\n",
      "step 4000, memory accuracy 0.842\n",
      "step 5000, memory accuracy 0.82\n",
      "step 6000, memory accuracy 0.834\n",
      "step 7000, memory accuracy 0.822\n",
      "step 8000, memory accuracy 0.826\n",
      "step 9000, memory accuracy 0.81\n",
      "step 10000, memory accuracy 0.83\n",
      "step 11000, memory accuracy 0.826\n",
      "step 12000, memory accuracy 0.822\n",
      "step 13000, memory accuracy 0.834\n",
      "step 14000, memory accuracy 0.822\n",
      "step 15000, memory accuracy 0.822\n",
      "step 16000, memory accuracy 0.822\n",
      "step 17000, memory accuracy 0.824\n",
      "step 18000, memory accuracy 0.822\n",
      "step 19000, memory accuracy 0.826\n",
      "step 20000, memory accuracy 0.83\n",
      "step 21000, memory accuracy 0.834\n",
      "step 22000, memory accuracy 0.824\n",
      "step 23000, memory accuracy 0.832\n",
      "21794\n",
      "step 0, memory accuracy 0.82\n",
      "step 1000, memory accuracy 0.81\n",
      "step 2000, memory accuracy 0.808\n",
      "step 3000, memory accuracy 0.81\n",
      "step 4000, memory accuracy 0.822\n",
      "step 5000, memory accuracy 0.806\n",
      "step 6000, memory accuracy 0.818\n",
      "step 7000, memory accuracy 0.814\n",
      "step 8000, memory accuracy 0.818\n",
      "step 9000, memory accuracy 0.806\n",
      "step 10000, memory accuracy 0.808\n",
      "step 11000, memory accuracy 0.814\n",
      "step 12000, memory accuracy 0.8\n",
      "step 13000, memory accuracy 0.822\n",
      "step 14000, memory accuracy 0.822\n",
      "step 15000, memory accuracy 0.82\n",
      "step 16000, memory accuracy 0.816\n",
      "step 17000, memory accuracy 0.818\n",
      "step 18000, memory accuracy 0.83\n",
      "step 19000, memory accuracy 0.816\n",
      "step 20000, memory accuracy 0.812\n",
      "step 21000, memory accuracy 0.812\n",
      "18082\n",
      "step 0, memory accuracy 0.796\n",
      "step 1000, memory accuracy 0.8\n",
      "step 2000, memory accuracy 0.79\n",
      "step 3000, memory accuracy 0.808\n",
      "step 4000, memory accuracy 0.77\n",
      "step 5000, memory accuracy 0.814\n",
      "step 6000, memory accuracy 0.8\n",
      "step 7000, memory accuracy 0.804\n",
      "step 8000, memory accuracy 0.8\n",
      "step 9000, memory accuracy 0.8\n",
      "step 10000, memory accuracy 0.796\n",
      "step 11000, memory accuracy 0.808\n",
      "step 12000, memory accuracy 0.806\n",
      "step 13000, memory accuracy 0.806\n",
      "step 14000, memory accuracy 0.8\n",
      "step 15000, memory accuracy 0.808\n",
      "step 16000, memory accuracy 0.804\n",
      "step 17000, memory accuracy 0.81\n",
      "16377\n",
      "step 0, memory accuracy 0.788\n",
      "step 1000, memory accuracy 0.784\n",
      "step 2000, memory accuracy 0.792\n",
      "step 3000, memory accuracy 0.772\n",
      "step 4000, memory accuracy 0.788\n",
      "step 5000, memory accuracy 0.758\n",
      "step 6000, memory accuracy 0.804\n",
      "step 7000, memory accuracy 0.754\n",
      "step 8000, memory accuracy 0.804\n",
      "step 9000, memory accuracy 0.788\n",
      "step 10000, memory accuracy 0.786\n",
      "step 11000, memory accuracy 0.784\n",
      "step 12000, memory accuracy 0.786\n",
      "step 13000, memory accuracy 0.794\n",
      "step 14000, memory accuracy 0.762\n",
      "step 15000, memory accuracy 0.784\n",
      "step 16000, memory accuracy 0.738\n"
     ]
    }
   ],
   "source": [
    "############################## Training  #######################\n",
    "\n",
    "batch_size = 10\n",
    "step_size = 100\n",
    "dataList=os.listdir('C:/OSU/SongMat/Train/')\n",
    "# acc=np.zeros([1000,1])\n",
    "\n",
    "n = 1\n",
    "total_steps = 0\n",
    "while n < np.size(dataList)-18:\n",
    "    n = n + 3\n",
    "    inputOsu=np.empty([0,128*128])\n",
    "    targetOsu=np.empty([0,4])\n",
    "    for k in range(n,n+15):\n",
    "        \n",
    "        data=sio.loadmat('C:/OSU/SongMat/Train/'+dataList[k])\n",
    "        inputOsu=np.append(inputOsu,data['input1'].reshape(-1,128*128),axis=0)\n",
    "        targetOsu=np.append(targetOsu,data['target1'].reshape(-1,4),axis=0)\n",
    "               \n",
    "    targetOsu2 = np.zeros([targetOsu.shape[0],2]);\n",
    "    targetOsu2[:,0] = targetOsu[:,0]+targetOsu[:,1]+targetOsu[:,2]\n",
    "    targetOsu2[:,1] = targetOsu[:,3]\n",
    "    \n",
    "    N=inputOsu.shape[0]\n",
    "    print(N)\n",
    "    \n",
    "    #shuffle the order\n",
    "    order = np.arange(N-step_size)\n",
    "    np.random.shuffle(order)\n",
    "    orderAcc = np.arange(NTest)\n",
    "    np.random.shuffle(orderAcc)\n",
    "    \n",
    "    for i in range(N-step_size):\n",
    "        if i%step_size == 0:\n",
    "            summary, _  = sess.run([merged, train_step], feed_dict={x: inputOsu[order[i:i+step_size],:], y_: targetOsu2[order[i:i+step_size],:], keep_prob: 0.5})\n",
    "            test_writer.add_summary(summary, i + total_steps)\n",
    "        else:\n",
    "            summary = sess.run(merged, feed_dict={x: inputOsu[order[i:i+step_size],:], y_: targetOsu2[order[i:i+step_size],:], keep_prob: 0.5})\n",
    "            train_writer.add_summary(summary, i + total_steps)\n",
    "        if i%1000 == 0:\n",
    "            accMemory = accuracy.eval(feed_dict={x: inputTest[orderAcc[0:500],:], y_: targetTest2[orderAcc[0:500],:], keep_prob: 1.0}) \n",
    "            print(\"step %d, memory accuracy %g\" %(i, accMemory))\n",
    "#             print(y.eval(feed_dict={x: inputTest[orderAcc[1122:1130],:], keep_prob: 1.0}))\n",
    "            \n",
    "    total_steps += i\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"D:/OSU/results/save/2.6/\",global_step=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Program Files (x86)\\\\osu!\\\\Songs\\\\532522 SakiZ - osu!memories\\\\']\n",
      "test accuracy 0.704\n"
     ]
    }
   ],
   "source": [
    "############################## Save the output of new maps ##############################\n",
    "\n",
    "dataList=os.listdir('C:/OSU/SongMat/Create/')\n",
    "# inputOsuNew=np.empty([0,128*128]);\n",
    "for i in range(np.size(dataList)):\n",
    "    if not dataList[i][0]=='y':\n",
    "        data=sio.loadmat('C:/OSU/SongMat/Create/'+dataList[i])\n",
    "        print(data['osuFolder'])\n",
    "        \n",
    "        inputOsuNew=data['input'].reshape(-1,128*128)\n",
    "        outputOsuNew=data['target']\n",
    "        outputOsu2New=np.zeros([outputOsuNew.shape[0],2]);\n",
    "        outputOsu2New[:,0]=outputOsuNew[:,0]+outputOsuNew[:,1]+outputOsuNew[:,2]\n",
    "        outputOsu2New[:,1]=outputOsuNew[:,3]\n",
    "        \n",
    "        y_result=np.empty([0,2])\n",
    "        \n",
    "        step_size=200\n",
    "        cursor=0\n",
    "        print (\"test accuracy %g\"%accuracy.eval(feed_dict={x: inputOsuNew[-500:,:], y_: outputOsu2New[-500:,:], keep_prob: 1.0}))\n",
    "        while cursor<inputOsuNew.shape[0]:\n",
    "            if inputOsuNew[cursor:,:].shape[0]>step_size:\n",
    "                y_result1=y.eval(feed_dict={x: inputOsuNew[cursor:(cursor+step_size):1,:], keep_prob: 1.0})\n",
    "                y_result=np.append(y_result,y_result1,axis=0)\n",
    "            else:\n",
    "                y_result1=y.eval(feed_dict={x: inputOsuNew[cursor:(cursor+step_size):1,:], keep_prob: 1.0})\n",
    "                y_result=np.append(y_result,y_result1,axis=0)\n",
    "            cursor+=step_size\n",
    "            \n",
    "        data_save={'y2':y_result}\n",
    "        sio.savemat('C:/OSU/SongMat/Create/y2_'+dataList[i],data_save)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
